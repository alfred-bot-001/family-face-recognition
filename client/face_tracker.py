"""äººè„¸è·Ÿè¸ªæ¨¡å— - èˆµæœºè·Ÿéšè¯†åˆ«åˆ°çš„å®¶äºº"""

import argparse
import json
import math
import threading
import time

import cv2
import numpy as np
import requests
import serial

# ============================================================
#  é…ç½®
# ============================================================

DEFAULT_API_URL = "http://192.168.0.69:8000"
DEFAULT_CAMERA = 0
DEFAULT_WIDTH = 640
DEFAULT_HEIGHT = 480
DEFAULT_FPS_LIMIT = 8       # API è¯†åˆ«å¸§ç‡
DEFAULT_PORT = 5000
DEFAULT_SERIAL = "/dev/ttyAMA0"
DEFAULT_BAUD = 115200

# è·Ÿè¸ªä¼˜å…ˆçº§ï¼ˆè¶Šé å‰è¶Šä¼˜å…ˆï¼‰
PRIORITY_NAMES = ["max", "son", "wife"]

# è¯­éŸ³é—®å€™é…ç½®ï¼ˆäººå‡ºç°åå†·å´æ—¶é—´å†…ä¸é‡å¤é—®å€™ï¼‰
GREET_COOLDOWN = 300  # ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
GREET_MESSAGES = {
    "son":  "ä½ å¥½ï¼Œå°è™ï¼",
    "max":  "è€å¤§å¥½ï¼",
    "wife": "å«‚å­å¥½ï¼",
}
GREET_DEFAULT = "ä½ å¥½ï¼"  # æœªçŸ¥å·²çŸ¥äººè„¸çš„é»˜è®¤é—®å€™

# èˆµæœºå‚æ•°ï¼ˆä¸ ugv_rpi/cv_ctrl.py æœºæ¢°é™ä½ä¸€è‡´ï¼‰
PAN_MIN, PAN_MAX = -180, 180      # æ°´å¹³èŒƒå›´
TILT_MIN, TILT_MAX = -30, 90      # å‚ç›´èŒƒå›´
TRACK_ITERATE = 0.045             # è·Ÿè¸ªæ­¥è¿›ç³»æ•°
TRACK_SPD_RATE = 60               # é€Ÿåº¦ç³»æ•°
TRACK_ACC_RATE = 0.4              # åŠ é€Ÿåº¦ç³»æ•°
AIMED_ERROR = 8                   # ç„å‡†è¯¯å·®é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
CMD_GIMBAL = 133                  # èˆµæœºæ§åˆ¶æŒ‡ä»¤ç 

# ============================================================
#  è¯­éŸ³é—®å€™
# ============================================================

class VoiceGreeter:
    """æ£€æµ‹åˆ°å®¶äººæ—¶è¯­éŸ³é—®å€™ï¼ˆå†·å´æ—¶é—´å†…ä¸é‡å¤ï¼‰"""

    def __init__(self, cooldown: float = GREET_COOLDOWN):
        self.cooldown = cooldown
        self.last_greet_time: dict[str, float] = {}  # name -> ä¸Šæ¬¡é—®å€™æ—¶é—´
        self.tts_lock = threading.Lock()
        self.engine = None
        self._init_tts()

    def _init_tts(self):
        """åˆå§‹åŒ– pyttsx3 TTS å¼•æ“ï¼ˆä¸ ugv_rpi/audio_ctrl.py ä¸€è‡´ï¼‰"""
        try:
            import pyttsx3
            self.engine = pyttsx3.init()
            self.engine.setProperty("rate", 180)  # è¯­é€Ÿ
            print("[è¯­éŸ³] TTS å¼•æ“å·²åˆå§‹åŒ–")
        except Exception as e:
            self.engine = None
            print(f"[è¯­éŸ³] TTS åˆå§‹åŒ–å¤±è´¥: {e}")

    def should_greet(self, name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é—®å€™ï¼ˆå†·å´æ—¶é—´å¤–ï¼‰"""
        if name == "unknown":
            return False
        last = self.last_greet_time.get(name, 0)
        return time.time() - last > self.cooldown

    def greet(self, name: str):
        """å¼‚æ­¥æ’­æ”¾é—®å€™è¯­éŸ³"""
        if not self.engine:
            return
        if not self.should_greet(name):
            return

        self.last_greet_time[name] = time.time()
        msg = GREET_MESSAGES.get(name, GREET_DEFAULT)
        add_log("INFO", f"ğŸ”Š è¯­éŸ³é—®å€™: {name} â†’ {msg}")

        threading.Thread(target=self._speak, args=(msg,), daemon=True).start()

    def _speak(self, text: str):
        """TTS æ’­æ”¾ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.tts_lock:
            try:
                self.engine.say(text)
                self.engine.runAndWait()
            except Exception as e:
                add_log("ERROR", f"è¯­éŸ³æ’­æ”¾å¤±è´¥: {e}")

    def check_faces(self, faces: list[dict]):
        """æ£€æŸ¥æ‰€æœ‰è¯†åˆ«åˆ°çš„äººè„¸ï¼Œè§¦å‘é—®å€™"""
        for face in faces:
            name = face.get("name", "unknown")
            if name != "unknown":
                self.greet(name)


# ============================================================
#  èˆµæœºæ§åˆ¶å™¨
# ============================================================

class GimbalController:
    """é€šè¿‡ä¸²å£æ§åˆ¶äº‘å°èˆµæœº"""

    def __init__(self, port: str = DEFAULT_SERIAL, baud: int = DEFAULT_BAUD):
        try:
            self.ser = serial.Serial(port, baud, timeout=1)
            self.connected = True
            print(f"[èˆµæœº] å·²è¿æ¥: {port} @ {baud}")
        except Exception as e:
            self.ser = None
            self.connected = False
            print(f"[èˆµæœº] è¿æ¥å¤±è´¥: {e}")

        self.pan_angle = 0.0    # å½“å‰æ°´å¹³è§’åº¦
        self.tilt_angle = 0.0   # å½“å‰å‚ç›´è§’åº¦
        self.lock = threading.Lock()

    def send_command(self, data: dict):
        """å‘é€ JSON æŒ‡ä»¤åˆ°åº•ç›˜"""
        if not self.connected:
            return
        try:
            cmd = json.dumps(data) + "\n"
            self.ser.write(cmd.encode("utf-8"))
        except Exception as e:
            print(f"[èˆµæœº] å‘é€å¤±è´¥: {e}")

    def move_to(self, pan: float, tilt: float, speed: int = 10, acc: int = 1):
        """ç»å¯¹ä½ç½®æ§åˆ¶"""
        with self.lock:
            self.pan_angle = max(PAN_MIN, min(PAN_MAX, pan))
            self.tilt_angle = max(TILT_MIN, min(TILT_MAX, tilt))
            self.send_command({
                "T": CMD_GIMBAL,
                "X": self.pan_angle,
                "Y": self.tilt_angle,
                "SPD": speed,
                "ACC": acc,
            })

    def track_target(self, frame_cx: int, frame_cy: int,
                     target_x: int, target_y: int,
                     iterate: float = TRACK_ITERATE) -> float:
        """
        è·Ÿè¸ªç›®æ ‡ï¼šæ ¹æ®ç›®æ ‡åœ¨ç”»é¢ä¸­çš„åç§»è°ƒæ•´èˆµæœº
        è¿”å›ç›®æ ‡åˆ°ç”»é¢ä¸­å¿ƒçš„è·ç¦»ï¼ˆåƒç´ ï¼‰
        """
        distance = math.sqrt((target_x - frame_cx) ** 2 + (frame_cy - target_y) ** 2)

        with self.lock:
            # è®¡ç®—è§’åº¦å¢é‡ï¼ˆä¸ ugv_rpi/cv_ctrl.py gimbal_track ä¸€è‡´ï¼‰
            self.pan_angle += (target_x - frame_cx) * iterate
            self.tilt_angle += (frame_cy - target_y) * iterate

            # é™å¹…
            self.pan_angle = max(PAN_MIN, min(PAN_MAX, self.pan_angle))
            self.tilt_angle = max(TILT_MIN, min(TILT_MAX, self.tilt_angle))

            # é€Ÿåº¦å’ŒåŠ é€Ÿåº¦æ ¹æ®è·ç¦»åŠ¨æ€è°ƒæ•´
            spd = max(1, int(distance * TRACK_SPD_RATE / 100))
            acc = max(1, int(distance * TRACK_ACC_RATE))

            self.send_command({
                "T": CMD_GIMBAL,
                "X": self.pan_angle,
                "Y": self.tilt_angle,
                "SPD": spd,
                "ACC": acc,
            })

        return distance

    def center(self):
        """å›ä¸­"""
        self.move_to(0, 0, speed=20, acc=5)

    def close(self):
        if self.ser:
            self.ser.close()

# ============================================================
#  äººè„¸è·Ÿè¸ªå™¨
# ============================================================

class FaceTracker:
    """ä» API è·å–è¯†åˆ«ç»“æœï¼Œé©±åŠ¨èˆµæœºè·Ÿè¸ªå®¶äºº"""

    def __init__(self, api_url: str, gimbal: GimbalController,
                 width: int = DEFAULT_WIDTH, height: int = DEFAULT_HEIGHT):
        self.api_url = api_url
        self.gimbal = gimbal
        self.width = width
        self.height = height
        self.center_x = width // 2
        self.center_y = height // 2

        # çŠ¶æ€
        self.tracking_name = None
        self.tracking_confidence = 0.0
        self.last_seen_time = 0.0
        self.lost_timeout = 3.0  # ä¸¢å¤±ç›®æ ‡åå¤šä¹…å›ä¸­

    def select_target(self, faces: list[dict]) -> dict | None:
        """
        ä»è¯†åˆ«ç»“æœä¸­é€‰æ‹©è·Ÿè¸ªç›®æ ‡
        ä¼˜å…ˆçº§ï¼šPRIORITY_NAMES ä¸­çš„é¡ºåº > æœ€å¤§äººè„¸
        """
        if not faces:
            return None

        # è¿‡æ»¤æ‰ unknown
        known_faces = [f for f in faces if f.get("name", "unknown") != "unknown"]

        if not known_faces:
            return None

        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©
        for priority_name in PRIORITY_NAMES:
            candidates = [f for f in known_faces if f["name"] == priority_name]
            if candidates:
                # å¤šä¸ªåŒåå–ç½®ä¿¡åº¦æœ€é«˜çš„
                return max(candidates, key=lambda f: f.get("confidence", 0))

        # æ²¡æœ‰ä¼˜å…ˆç›®æ ‡ï¼Œå–ç½®ä¿¡åº¦æœ€é«˜çš„å·²çŸ¥äººè„¸
        return max(known_faces, key=lambda f: f.get("confidence", 0))

    def get_face_center(self, face: dict) -> tuple[int, int]:
        """è·å–äººè„¸ä¸­å¿ƒåæ ‡"""
        bbox = face.get("bbox", [0, 0, 0, 0])
        cx = (bbox[0] + bbox[2]) // 2
        cy = (bbox[1] + bbox[3]) // 2
        return cx, cy

    def update(self, faces: list[dict]):
        """æ ¹æ®è¯†åˆ«ç»“æœæ›´æ–°è·Ÿè¸ª"""
        target = self.select_target(faces)

        if target:
            self.tracking_name = target["name"]
            self.tracking_confidence = target.get("confidence", 0)
            self.last_seen_time = time.time()

            tx, ty = self.get_face_center(target)
            distance = self.gimbal.track_target(
                self.center_x, self.center_y, tx, ty
            )

            if distance < AIMED_ERROR:
                status = "ğŸ¯ é”å®š"
            else:
                status = "ğŸ”„ è¿½è¸ª"

            print(f"  {status} {self.tracking_name} "
                  f"(ç½®ä¿¡åº¦: {self.tracking_confidence:.2f}, "
                  f"åç§»: {distance:.0f}px, "
                  f"èˆµæœº: {self.gimbal.pan_angle:.1f}Â°, {self.gimbal.tilt_angle:.1f}Â°)")
        else:
            # æ²¡æœ‰ç›®æ ‡
            if self.tracking_name and time.time() - self.last_seen_time > self.lost_timeout:
                print(f"  âš ï¸ ä¸¢å¤±ç›®æ ‡ {self.tracking_name}ï¼Œå›ä¸­...")
                self.gimbal.center()
                self.tracking_name = None

# ============================================================
#  ä¸»å¾ªç¯ï¼ˆæ‘„åƒå¤´ + API + è·Ÿè¸ª + Webï¼‰
# ============================================================

from flask import Flask, Response, jsonify, send_from_directory

# å…¨å±€çŠ¶æ€
latest_frame: np.ndarray | None = None
latest_results: list[dict] = []
tracker_status: dict = {}
is_running = True
lock = threading.Lock()

# æ—¥å¿—ç¼“å†²
from collections import deque
log_buffer = deque(maxlen=100)

def add_log(level: str, msg: str):
    """æ·»åŠ ç³»ç»Ÿæ—¥å¿—"""
    ts = time.strftime("%H:%M:%S")
    entry = {"time": ts, "level": level, "msg": msg}
    log_buffer.appendleft(entry)
    print(f"[{level}] {ts} {msg}")

flask_app = Flask(__name__, static_folder="static")


def draw_tracking_results(frame: np.ndarray, faces: list[dict],
                          tracking_name: str | None) -> np.ndarray:
    """åœ¨å¸§ä¸Šç»˜åˆ¶è¯†åˆ«ç»“æœï¼Œé«˜äº®è·Ÿè¸ªç›®æ ‡"""
    annotated = frame.copy()
    for f in faces:
        bbox = f.get("bbox", [])
        if len(bbox) != 4:
            continue
        x1, y1, x2, y2 = [int(v) for v in bbox]
        name = f.get("name", "unknown")
        conf = f.get("confidence", 0)
        is_target = (name == tracking_name)

        if is_target:
            color = (0, 255, 255)  # é»„è‰² = è·Ÿè¸ªç›®æ ‡
            thickness = 3
        elif name != "unknown":
            color = (0, 255, 0)    # ç»¿è‰² = å·²çŸ¥
            thickness = 2
        else:
            color = (0, 0, 255)    # çº¢è‰² = æœªçŸ¥
            thickness = 1

        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, thickness)

        label = f"{'>>> ' if is_target else ''}{name} ({conf:.2f})"
        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
        cv2.rectangle(annotated, (x1, y1 - h - 8), (x1 + w, y1), color, -1)
        cv2.putText(annotated, label, (x1, y1 - 4),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

    # ç”»ä¸­å¿ƒåå­—å‡†æ˜Ÿ
    h, w = annotated.shape[:2]
    cx, cy = w // 2, h // 2
    cv2.line(annotated, (cx - 15, cy), (cx + 15, cy), (255, 255, 255), 1)
    cv2.line(annotated, (cx, cy - 15), (cx, cy + 15), (255, 255, 255), 1)

    return annotated


def open_camera(camera_id: int, width: int, height: int):
    """
    æ‰“å¼€æ‘„åƒå¤´ï¼ˆOpenCV ç»Ÿä¸€å¤„ç† USB å’Œ CSIï¼‰
    RPi5 ä¸Š OpenCV é€šè¿‡ V4L2/GStreamer å¯ç›´æ¥è®¿é—® CSI æ‘„åƒå¤´
    """
    cap = cv2.VideoCapture(camera_id)
    if cap.isOpened():
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        ret, frame = cap.read()
        if ret:
            actual_h, actual_w = frame.shape[:2]
            add_log("INFO", f"æ‘„åƒå¤´å·²æ‰“å¼€: /dev/video{camera_id} ({actual_w}x{actual_h})")
            return ("opencv", cap)
        else:
            cap.release()
            add_log("WARN", f"æ‘„åƒå¤´ {camera_id} æ‰“å¼€æˆåŠŸä½†è¯»å–å¤±è´¥")
    else:
        add_log("WARN", f"æ‘„åƒå¤´ {camera_id} æ— æ³•æ‰“å¼€")

    add_log("ERROR", "æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
    return (None, None)


def read_frame(cam_type, cam_obj):
    """ä»æ‘„åƒå¤´è¯»å–ä¸€å¸§ï¼Œè¿”å› BGR numpy æ•°ç»„"""
    try:
        ret, frame = cam_obj.read()
        return frame if ret else None
    except Exception as e:
        add_log("ERROR", f"è¯»å–å¸§å¼‚å¸¸: {e}")
    return None


def close_camera(cam_type, cam_obj):
    """å…³é—­æ‘„åƒå¤´"""
    try:
        cam_obj.release()
    except Exception as e:
        add_log("WARN", f"å…³é—­æ‘„åƒå¤´å¼‚å¸¸: {e}")


def make_placeholder_frame(width: int, height: int, text: str = "æ‘„åƒå¤´æœªè¿æ¥") -> np.ndarray:
    """ç”Ÿæˆå ä½å›¾ï¼ˆå‚è€ƒ ugv_rpi çš„ camera read failed ç”»é¢ï¼‰"""
    frame = np.zeros((height, width, 3), dtype=np.uint8)
    frame[:] = (30, 30, 30)
    # ä¸­å¿ƒæ–‡å­—
    font = cv2.FONT_HERSHEY_SIMPLEX
    scale = 0.7
    (tw, th), _ = cv2.getTextSize(text, font, scale, 2)
    x = (width - tw) // 2
    y = (height + th) // 2
    cv2.putText(frame, text, (x, y), font, scale, (0, 0, 255), 2)
    return frame


def camera_tracking_loop(api_url: str, camera_id: int, width: int, height: int,
                         fps_limit: int, gimbal: GimbalController,
                         greeter: VoiceGreeter):
    """ä¸»å¾ªç¯ï¼šæ‘„åƒå¤´ â†’ API â†’ è·Ÿè¸ª â†’ èˆµæœº â†’ è¯­éŸ³"""
    global latest_frame, latest_results, tracker_status, is_running

    tracker = FaceTracker(api_url, gimbal, width, height)

    cam_type, cam_obj = open_camera(camera_id, width, height)
    retry_interval = 5  # æ‘„åƒå¤´é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
    last_retry = 0
    frame_interval = 1.0 / fps_limit
    last_send = 0
    frame_count = 0
    api_ok_count = 0
    api_err_count = 0
    read_fail_count = 0

    while is_running:
        # æ²¡æœ‰æ‘„åƒå¤´æ—¶ï¼šæ˜¾ç¤ºå ä½å›¾ + å®šæœŸé‡è¯•
        if cam_type is None:
            with lock:
                latest_frame = make_placeholder_frame(width, height, "Camera Disconnected - Retrying...")
            now = time.time()
            if now - last_retry > retry_interval:
                last_retry = now
                add_log("INFO", "å°è¯•é‡æ–°è¿æ¥æ‘„åƒå¤´...")
                cam_type, cam_obj = open_camera(camera_id, width, height)
            time.sleep(0.2)
            continue

        frame = read_frame(cam_type, cam_obj)
        if frame is None:
            read_fail_count += 1
            if read_fail_count == 1:
                add_log("WARN", "è¯»å–å¸§å¤±è´¥ï¼Œå°è¯•ä¸­...")
            if read_fail_count > 30:
                add_log("ERROR", f"è¿ç»­ {read_fail_count} æ¬¡è¯»å–å¤±è´¥ï¼Œé‡æ–°æ‰“å¼€æ‘„åƒå¤´")
                close_camera(cam_type, cam_obj)
                cam_type, cam_obj = None, None
                read_fail_count = 0
            time.sleep(0.1)
            continue

        read_fail_count = 0
        frame_count += 1
        if frame_count == 1:
            add_log("INFO", f"é¦–å¸§è·å–æˆåŠŸ: {frame.shape}")

        now = time.time()

        # éè¯†åˆ«å¸§ï¼šç”¨ä¸Šæ¬¡ç»“æœæ›´æ–°æ˜¾ç¤º
        if now - last_send < frame_interval:
            with lock:
                latest_frame = draw_tracking_results(frame, latest_results, tracker.tracking_name)
            continue

        last_send = now

        # ç¼–ç å‘é€
        _, jpeg = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
        try:
            resp = requests.post(
                f"{api_url}/recognize",
                files={"file": ("frame.jpg", jpeg.tobytes(), "image/jpeg")},
                timeout=5,
            )
            if resp.status_code == 200:
                data = resp.json()
                faces = data.get("faces", [])
                api_ok_count += 1

                if api_ok_count == 1:
                    add_log("INFO", f"API é¦–æ¬¡å“åº”æˆåŠŸï¼Œæ£€æµ‹åˆ° {len(faces)} å¼ è„¸")

                # æ›´æ–°è·Ÿè¸ª
                tracker.update(faces)

                # è¯­éŸ³é—®å€™
                greeter.check_faces(faces)

                with lock:
                    latest_results = faces
                    latest_frame = draw_tracking_results(frame, faces, tracker.tracking_name)
                    tracker_status = {
                        "tracking": tracker.tracking_name,
                        "confidence": round(tracker.tracking_confidence, 3),
                        "pan": round(gimbal.pan_angle, 1),
                        "tilt": round(gimbal.tilt_angle, 1),
                        "faces_count": len(faces),
                        "known_count": len([f for f in faces if f.get("name") != "unknown"]),
                        "frame_count": frame_count,
                        "api_ok": api_ok_count,
                        "api_err": api_err_count,
                        "greet_history": {k: time.strftime("%H:%M:%S", time.localtime(v))
                                          for k, v in greeter.last_greet_time.items()},
                    }
            else:
                api_err_count += 1
                add_log("ERROR", f"API HTTP {resp.status_code}")
        except requests.exceptions.RequestException as e:
            api_err_count += 1
            if api_err_count <= 3 or api_err_count % 10 == 0:
                add_log("ERROR", f"API è¿æ¥å¤±è´¥: {e}")
            with lock:
                latest_results = []
                latest_frame = draw_tracking_results(frame, [], None)

    close_camera(cam_type, cam_obj)
    gimbal.center()
    gimbal.close()


# ============================================================
#  Flask è·¯ç”±
# ============================================================

def generate_mjpeg():
    while is_running:
        with lock:
            frame = latest_frame
        if frame is None:
            time.sleep(0.05)
            continue
        _, jpeg = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 75])
        yield (
            b"--frame\r\n"
            b"Content-Type: image/jpeg\r\n\r\n" + jpeg.tobytes() + b"\r\n"
        )
        time.sleep(0.033)


@flask_app.route("/")
def index():
    return send_from_directory("static", "tracker.html")


@flask_app.route("/video_feed")
def video_feed():
    return Response(
        generate_mjpeg(),
        mimetype="multipart/x-mixed-replace; boundary=frame",
    )


@flask_app.route("/api/status")
def api_status():
    with lock:
        return jsonify({
            **tracker_status,
            "faces": latest_results.copy(),
            "running": is_running,
        })


@flask_app.route("/api/logs")
def api_logs():
    return jsonify(list(log_buffer))


@flask_app.route("/api/gimbal/center", methods=["POST"])
def gimbal_center():
    """æ‰‹åŠ¨å›ä¸­"""
    gimbal_instance.center()
    return jsonify({"ok": True})


# ============================================================
#  å…¥å£
# ============================================================

gimbal_instance: GimbalController = None


def main():
    global is_running, gimbal_instance

    parser = argparse.ArgumentParser(description="å®¶åº­äººè„¸è·Ÿè¸ª - èˆµæœºè¿½è¸ªå®¶äºº")
    parser.add_argument("--api", default=DEFAULT_API_URL, help="API åœ°å€")
    parser.add_argument("--camera", type=int, default=DEFAULT_CAMERA, help="æ‘„åƒå¤´ç¼–å·")
    parser.add_argument("--width", type=int, default=DEFAULT_WIDTH)
    parser.add_argument("--height", type=int, default=DEFAULT_HEIGHT)
    parser.add_argument("--fps", type=int, default=DEFAULT_FPS_LIMIT, help="è¯†åˆ«å¸§ç‡")
    parser.add_argument("--port", type=int, default=DEFAULT_PORT, help="Web ç«¯å£")
    parser.add_argument("--serial", default=DEFAULT_SERIAL, help="èˆµæœºä¸²å£")
    parser.add_argument("--baud", type=int, default=DEFAULT_BAUD, help="æ³¢ç‰¹ç‡")
    parser.add_argument("--no-gimbal", action="store_true", help="ç¦ç”¨èˆµæœºï¼ˆä»…æ˜¾ç¤ºï¼‰")
    args = parser.parse_args()

    print(f"{'='*50}")
    print(f"  å®¶åº­äººè„¸è·Ÿè¸ª - èˆµæœºè¿½è¸ªæ¨¡å¼")
    print(f"  API: {args.api}")
    print(f"  æ‘„åƒå¤´: {args.camera} ({args.width}x{args.height})")
    print(f"  èˆµæœº: {args.serial} ({'ç¦ç”¨' if args.no_gimbal else 'å¯ç”¨'})")
    print(f"  è·Ÿè¸ªä¼˜å…ˆçº§: {' > '.join(PRIORITY_NAMES)}")
    print(f"  Web: http://0.0.0.0:{args.port}")
    print(f"{'='*50}")

    # åˆå§‹åŒ–èˆµæœº
    if args.no_gimbal:
        gimbal_instance = GimbalController.__new__(GimbalController)
        gimbal_instance.connected = False
        gimbal_instance.ser = None
        gimbal_instance.pan_angle = 0
        gimbal_instance.tilt_angle = 0
        gimbal_instance.lock = threading.Lock()
    else:
        gimbal_instance = GimbalController(args.serial, args.baud)
        gimbal_instance.center()
        time.sleep(0.5)

    # åˆå§‹åŒ–è¯­éŸ³é—®å€™
    greeter_instance = VoiceGreeter(cooldown=GREET_COOLDOWN)

    # å¯åŠ¨æ‘„åƒå¤´+è·Ÿè¸ªçº¿ç¨‹
    cam_thread = threading.Thread(
        target=camera_tracking_loop,
        args=(args.api, args.camera, args.width, args.height, args.fps,
              gimbal_instance, greeter_instance),
        daemon=True,
    )
    cam_thread.start()

    # Flask
    try:
        flask_app.run(host="0.0.0.0", port=args.port, threaded=True)
    except KeyboardInterrupt:
        pass
    finally:
        is_running = False
        cam_thread.join(timeout=3)
        if gimbal_instance.connected:
            gimbal_instance.center()
            gimbal_instance.close()
        print("[å®Œæˆ] å·²é€€å‡º")


if __name__ == "__main__":
    main()
