#!/usr/bin/env python3
"""
Â∞èÊô∫ËØ≠Èü≥ÂØπËØùÂÆ¢Êà∑Á´Ø ‚Äî ËøêË°åÂú®ËÄÅ‰∏â(Ê†ëËéìÊ¥æ)‰∏ä
Âî§ÈÜíËØç: "ÊÇüÁ©∫ÊÇüÁ©∫" (sherpa-onnx KeywordSpotter)
‰øùÊåÅ WebSocket ÈïøËøûÊé•ÔºåÊ£ÄÊµãÂî§ÈÜíËØçÂêéÂºÄÂßãÂΩïÈü≥ÂØπËØù

ÂèÇËÄÉ: py-xiaozhi È°πÁõÆÂçèËÆÆÂÆûÁé∞
"""

import argparse
import asyncio
import json
import logging
import os
import subprocess
import sys
import threading
import time
import uuid

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
log = logging.getLogger("xiaozhi")

# ============================================================
#  ÈÖçÁΩÆ
# ============================================================
SAMPLE_RATE = 16000
CHANNELS = 1
FRAME_DURATION_MS = 60
FRAME_SIZE = SAMPLE_RATE * FRAME_DURATION_MS // 1000  # 960
AUDIO_PLAY = "plughw:3,0"
AUDIO_REC = "plughw:2,0"
WAKE_WORD = "ÊóãÈ£éÊàòËΩ¶"
VOSK_MODEL = os.path.join(os.path.dirname(__file__), "models", "vosk-model-small-cn-0.22")

# ============================================================
#  Opus
# ============================================================
import opuslib_next as opuslib
_encoder = opuslib.Encoder(SAMPLE_RATE, CHANNELS, opuslib.APPLICATION_VOIP)
_decoder = opuslib.Decoder(SAMPLE_RATE, CHANNELS)

def pcm_to_opus(pcm: bytes) -> bytes:
    return _encoder.encode(pcm, FRAME_SIZE)

def opus_to_pcm(data: bytes) -> bytes:
    return _decoder.decode(data, FRAME_SIZE)

# ============================================================
#  Êú¨Âú∞ TTS
# ============================================================
def speak(text: str):
    subprocess.run(
        f'espeak -v zh -s 320 --stdout "{text}" | aplay -D {AUDIO_PLAY} -q',
        shell=True, stderr=subprocess.DEVNULL
    )

def speak_async(text: str):
    threading.Thread(target=speak, args=(text,), daemon=True).start()

# ============================================================
#  Âî§ÈÜíËØçÊ£ÄÊµã (vosk)
# ============================================================
class WakeWordListener:
    def __init__(self, device=AUDIO_REC):
        from vosk import Model, KaldiRecognizer
        log.info(f"Âä†ËΩΩ vosk Ê®°Âûã: {VOSK_MODEL}")
        self.model = Model(VOSK_MODEL)
        self.recognizer = KaldiRecognizer(self.model, SAMPLE_RATE)
        self.device = device
        self.paused = False
        self.active = True
        self._proc = None
        self._cooldown = 2.0
        self._last_detect = 0

    def start(self, on_wake):
        threading.Thread(target=self._listen, args=(on_wake,), daemon=True).start()

    def _listen(self, on_wake):
        log.info(f"üëÇ ÁõëÂê¨Âî§ÈÜíËØç: {WAKE_WORD}")
        self._proc = subprocess.Popen(
            ["arecord", "-D", self.device, "-f", "S16_LE",
             "-r", str(SAMPLE_RATE), "-c", "1", "-t", "raw", "-q"],
            stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
        )
        chunk = 4000
        while self.active and self._proc.poll() is None:
            data = self._proc.stdout.read(chunk)
            if not data or self.paused:
                continue
            if self.recognizer.AcceptWaveform(data):
                result = json.loads(self.recognizer.Result())
                text = result.get("text", "")
                if text:
                    log.info(f"vosk: {text}")
                    if WAKE_WORD in text:
                        self._trigger(on_wake, text)
            else:
                partial = json.loads(self.recognizer.PartialResult())
                text = partial.get("partial", "")
                if WAKE_WORD in text:
                    self._trigger(on_wake, f"partial: {text}")

    def _trigger(self, on_wake, text):
        now = time.time()
        if now - self._last_detect < self._cooldown:
            return
        self._last_detect = now
        log.info(f"üéØ Âî§ÈÜíËØç! ({text})")
        self.recognizer.Reset()
        on_wake()

    def pause(self):
        self.paused = True

    def resume(self):
        self.paused = False
        self.recognizer.Reset()

    def stop(self):
        self.active = False
        if self._proc:
            self._proc.terminate()

# ============================================================
#  Â∞èÊô∫ÂÆ¢Êà∑Á´Ø (ÈïøËøûÊé•)
# ============================================================
class XiaozhiClient:
    def __init__(self, ws_url: str, device_id: str):
        self.ws_url = ws_url
        self.device_id = device_id
        self.session_id = None
        self.ws = None
        self.connected = False
        self.is_speaking = False  # ÊúçÂä°Á´ØÂú®ËØ¥ËØù
        self.is_listening = False  # Ê≠£Âú®ÂΩïÈü≥
        self._rec_proc = None
        self._play_proc = None
        self._loop = None
        self._send_task = None

    async def connect(self):
        """Âª∫Á´ãÈïøËøûÊé•"""
        import websockets
        headers = {
            "Device-Id": self.device_id,
            "Client-Id": self.device_id,
            "Protocol-Version": "1",
        }
        log.info(f"üîó ËøûÊé• {self.ws_url}")
        try:
            self.ws = await websockets.connect(
                self.ws_url, max_size=None,
                additional_headers=headers,
                ping_interval=20, ping_timeout=20,
                close_timeout=10,
            )
        except TypeError:
            self.ws = await websockets.connect(
                self.ws_url, max_size=None,
                extra_headers=headers,
                ping_interval=20, ping_timeout=20,
                close_timeout=10,
            )
        # Âèë hello
        hello = {
            "type": "hello",
            "version": 1,
            "transport": "websocket",
            "device_id": self.device_id,
            "device_name": "ËÄÅ‰∏â-Ê†ëËéìÊ¥æ",
            "features": {"mcp": False},
            "audio_params": {
                "format": "opus",
                "sample_rate": SAMPLE_RATE,
                "channels": CHANNELS,
                "frame_duration": FRAME_DURATION_MS,
            },
        }
        await self.ws.send(json.dumps(hello))
        log.info("üì§ Â∑≤ÂèëÈÄÅ hello")

        # Á≠â hello ÂìçÂ∫î
        resp = await asyncio.wait_for(self.ws.recv(), timeout=10)
        try:
            data = json.loads(resp)
            self.session_id = data.get("session_id", "")
            log.info(f"‚úÖ ËøûÊé•ÊàêÂäü, session: {self.session_id}")
            self.connected = True
        except Exception as e:
            log.error(f"Êè°ÊâãÂ§±Ë¥•: {e}, resp: {str(resp)[:200]}")
            return False
        return True

    async def message_loop(self):
        """ÊåÅÁª≠Êé•Êî∂Ê∂àÊÅØ"""
        try:
            async for message in self.ws:
                if isinstance(message, bytes):
                    # Opus Èü≥È¢ë ‚Üí Ëß£Á†ÅÊí≠Êîæ
                    self._audio_count = getattr(self, '_audio_count', 0) + 1
                    if self._audio_count <= 3 or self._audio_count % 50 == 0:
                        log.info(f"üîà Êî∂Âà∞Èü≥È¢ëÂ∏ß #{self._audio_count}, {len(message)} bytes")
                    try:
                        pcm = opus_to_pcm(message)
                        self._play_pcm(pcm)
                    except Exception as e:
                        log.error(f"Èü≥È¢ëËß£Á†Å/Êí≠ÊîæÈîôËØØ: {e}")
                else:
                    data = json.loads(message)
                    await self._handle(data)
        except Exception as e:
            log.error(f"ËøûÊé•Êñ≠ÂºÄ: {e}")
            self.connected = False

    async def _handle(self, msg: dict):
        t = msg.get("type", "")
        if t == "tts":
            state = msg.get("state", "")
            if state == "start":
                self.is_speaking = True
                log.info("üîä ÊúçÂä°Á´ØÂºÄÂßãËØ¥ËØù")
            elif state == "sentence_start":
                log.info(f"üí¨ {msg.get('text', '')}")
            elif state == "stop":
                self.is_speaking = False
                log.info("üîä ÊúçÂä°Á´ØËØ¥ËØùÁªìÊùü")
        elif t == "stt":
            log.info(f"üé§ ËØÜÂà´: {msg.get('text', '')}")
        elif t == "llm":
            log.info(f"ü§ñ {msg.get('text', '')}")
        elif t == "hello":
            self.session_id = msg.get("session_id", self.session_id)
            log.info(f"hello ÂìçÂ∫î, session: {self.session_id}")

    def _play_pcm(self, pcm: bytes):
        """Áõ¥Êé•ÂÜôÂÖ• aplay ËøõÁ®ã"""
        try:
            if self._play_proc is None or self._play_proc.poll() is not None:
                log.info(f"üîä ÂêØÂä® aplay ËøõÁ®ã (ËÆæÂ§á: {AUDIO_PLAY}, ÈááÊ†∑Áéá: {SAMPLE_RATE})")
                self._play_proc = subprocess.Popen(
                    ["aplay", "-D", AUDIO_PLAY, "-f", "S16_LE",
                     "-r", str(SAMPLE_RATE), "-c", "1", "-q"],
                    stdin=subprocess.PIPE, stderr=subprocess.PIPE
                )
            self._play_proc.stdin.write(pcm)
            self._play_proc.stdin.flush()
        except Exception as e:
            log.error(f"Êí≠ÊîæÈîôËØØ: {e}")
            if self._play_proc:
                err = self._play_proc.stderr.read(200) if self._play_proc.stderr else b""
                log.error(f"aplay stderr: {err}")
            self._play_proc = None

    async def on_wake_word(self):
        """Âî§ÈÜíËØçËß¶Âèë"""
        if not self.connected:
            log.warning("Êú™ËøûÊé•ÔºåÂøΩÁï•Âî§ÈÜí")
            return

        log.info("üéôÔ∏è Âî§ÈÜíËØçËß¶ÂèëÔºåÂºÄÂßãÂØπËØù")

        # Â¶ÇÊûúÊúçÂä°Á´ØÂú®ËØ¥ËØùÔºåÂÖàÊâìÊñ≠
        if self.is_speaking:
            abort = {"session_id": self.session_id, "type": "abort", "reason": "wake_word_detected"}
            await self.ws.send(json.dumps(abort))
            # ÂÖ≥Èó≠Êí≠ÊîæËøõÁ®ã
            if self._play_proc:
                try:
                    self._play_proc.terminate()
                except Exception:
                    pass
                self._play_proc = None

        # ÂèëÂî§ÈÜíËØçÊ£ÄÊµãÊ∂àÊÅØ
        detect = {
            "session_id": self.session_id,
            "type": "listen",
            "state": "detect",
            "text": WAKE_WORD,
        }
        await self.ws.send(json.dumps(detect))

        # ÂèëÂºÄÂßãÁõëÂê¨
        start = {
            "session_id": self.session_id,
            "type": "listen",
            "state": "start",
            "mode": "auto",
        }
        await self.ws.send(json.dumps(start))

        # ÂºÄÂßãÂΩïÈü≥ÂèëÈÄÅ
        self.is_listening = True
        self._send_task = asyncio.create_task(self._record_and_send())

    async def _record_and_send(self):
        """ÂΩïÈü≥Âπ∂ÈÄöËøá WebSocket ÂèëÈÄÅ Opus Â∏ß"""
        frame_bytes = FRAME_SIZE * 2
        self._rec_proc = subprocess.Popen(
            ["arecord", "-D", AUDIO_REC, "-f", "S16_LE",
             "-r", str(SAMPLE_RATE), "-c", "1", "-t", "raw", "-q"],
            stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
        )
        loop = asyncio.get_event_loop()
        log.info("üéôÔ∏è ÂΩïÈü≥‰∏≠...")
        try:
            while self.is_listening and self.connected:
                data = await loop.run_in_executor(None, self._rec_proc.stdout.read, frame_bytes)
                if len(data) == frame_bytes:
                    opus = pcm_to_opus(data)
                    await self.ws.send(opus)
        except Exception as e:
            log.error(f"ÂΩïÈü≥ÂèëÈÄÅÈîôËØØ: {e}")
        finally:
            self._stop_recording()

    def _stop_recording(self):
        self.is_listening = False
        if self._rec_proc:
            try:
                self._rec_proc.terminate()
            except Exception:
                pass
            self._rec_proc = None

    async def stop_listening(self):
        """ÂÅúÊ≠¢ÂΩïÈü≥"""
        self._stop_recording()
        if self._send_task:
            self._send_task.cancel()
        stop = {"session_id": self.session_id, "type": "listen", "state": "stop"}
        try:
            await self.ws.send(json.dumps(stop))
        except Exception:
            pass
        log.info("üéôÔ∏è ÂÅúÊ≠¢ÂΩïÈü≥")


# ============================================================
#  ‰∏ªÁ®ãÂ∫è
# ============================================================
async def main(ws_url: str):
    device_id = f"pi-{uuid.uuid4().hex[:8]}"
    log.info(f"ËÆæÂ§áID: {device_id}")

    client = XiaozhiClient(ws_url, device_id)

    # ËøûÊé•
    if not await client.connect():
        log.error("ËøûÊé•Â§±Ë¥•ÔºåÈÄÄÂá∫")
        return

    speak_async("ÊÇüÁ©∫‰∏äÁ∫ø‰∫Ü")

    # Âî§ÈÜíËØçÁõëÂê¨
    listener = WakeWordListener()
    loop = asyncio.get_event_loop()

    def on_wake():
        listener.pause()
        asyncio.run_coroutine_threadsafe(client.on_wake_word(), loop)
        # Á≠âÊúçÂä°Á´ØËØ¥ÂÆåÂêéÊÅ¢Â§çÁõëÂê¨
        def wait_and_resume():
            time.sleep(2)  # Á≠âÂî§ÈÜíÂ§ÑÁêÜ
            while client.is_listening or client.is_speaking:
                time.sleep(0.5)
            time.sleep(1)
            listener.resume()
            log.info(f"üëÇ ÁªßÁª≠ÁõëÂê¨: {WAKE_WORD}")
        threading.Thread(target=wait_and_resume, daemon=True).start()

    listener.start(on_wake)

    # Ê∂àÊÅØÂæ™ÁéØÔºà‰øùÊåÅÈïøËøûÊé•Ôºâ
    await client.message_loop()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Â∞èÊô∫ËØ≠Èü≥ÂØπËØùÂÆ¢Êà∑Á´Ø")
    parser.add_argument("--ws", default="ws://192.168.0.69:8100/xiaozhi/v1/")
    parser.add_argument("--play-device", default=AUDIO_PLAY)
    parser.add_argument("--rec-device", default=AUDIO_REC)
    args = parser.parse_args()

    AUDIO_PLAY = args.play_device
    AUDIO_REC = args.rec_device

    asyncio.run(main(args.ws))
