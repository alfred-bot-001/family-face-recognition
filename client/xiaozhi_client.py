#!/usr/bin/env python3
"""
å°æ™ºè¯­éŸ³å¯¹è¯å®¢æˆ·ç«¯ â€” è¿è¡Œåœ¨è€ä¸‰(æ ‘è“æ´¾)ä¸Š
å”¤é†’è¯: "æ‚Ÿç©º" (vosk ç¦»çº¿è¯†åˆ«)
ä¿æŒ WebSocket é•¿è¿æ¥ï¼Œæ£€æµ‹å”¤é†’è¯åå¼€å§‹å½•éŸ³å¯¹è¯

å‚è€ƒ: py-xiaozhi é¡¹ç›®åè®®å®ç°
"""

import argparse
import asyncio
import json
import logging
import os
import subprocess
import sys
import threading
import time
import uuid

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
log = logging.getLogger("xiaozhi")

# ============================================================
#  é…ç½®
# ============================================================
SAMPLE_RATE = 16000
CHANNELS = 1
FRAME_DURATION_MS = 60
FRAME_SIZE = SAMPLE_RATE * FRAME_DURATION_MS // 1000  # 960
AUDIO_PLAY = "plughw:3,0"
AUDIO_REC = "plughw:2,0"
WAKE_WORD = "æ‚Ÿç©º"
VOSK_MODEL = os.path.join(os.path.dirname(__file__), "models", "vosk-model-small-cn-0.22")

# ============================================================
#  Opus
# ============================================================
import opuslib_next as opuslib
_encoder = opuslib.Encoder(SAMPLE_RATE, CHANNELS, opuslib.APPLICATION_VOIP)
_decoder = opuslib.Decoder(SAMPLE_RATE, CHANNELS)

def pcm_to_opus(pcm: bytes) -> bytes:
    return _encoder.encode(pcm, FRAME_SIZE)

def opus_to_pcm(data: bytes) -> bytes:
    return _decoder.decode(data, FRAME_SIZE)

# ============================================================
#  æœ¬åœ° TTS
# ============================================================
def speak(text: str):
    subprocess.run(
        f'espeak -v zh -s 320 --stdout "{text}" | aplay -D {AUDIO_PLAY} -q',
        shell=True, stderr=subprocess.DEVNULL
    )

def speak_async(text: str):
    threading.Thread(target=speak, args=(text,), daemon=True).start()

# ============================================================
#  å”¤é†’è¯æ£€æµ‹ (vosk)
# ============================================================
class WakeWordListener:
    def __init__(self, device=AUDIO_REC):
        from vosk import Model, KaldiRecognizer
        log.info(f"åŠ è½½ vosk æ¨¡å‹: {VOSK_MODEL}")
        self.model = Model(VOSK_MODEL)
        self.recognizer = KaldiRecognizer(self.model, SAMPLE_RATE)
        self.device = device
        self.paused = False
        self.active = True
        self._proc = None

    def start(self, on_wake):
        """åå°çº¿ç¨‹ç›‘å¬å”¤é†’è¯"""
        threading.Thread(target=self._listen, args=(on_wake,), daemon=True).start()

    def _listen(self, on_wake):
        log.info(f"ğŸ‘‚ ç›‘å¬å”¤é†’è¯: {WAKE_WORD}")
        self._proc = subprocess.Popen(
            ["arecord", "-D", self.device, "-f", "S16_LE",
             "-r", str(SAMPLE_RATE), "-c", "1", "-t", "raw", "-q"],
            stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
        )
        chunk = 4000
        while self.active and self._proc.poll() is None:
            data = self._proc.stdout.read(chunk)
            if not data or self.paused:
                continue
            if self.recognizer.AcceptWaveform(data):
                result = json.loads(self.recognizer.Result())
                text = result.get("text", "")
                if text:
                    log.info(f"vosk: {text}")
                    if WAKE_WORD in text:
                        log.info(f"ğŸ¯ å”¤é†’è¯! ({text})")
                        on_wake()
            else:
                partial = json.loads(self.recognizer.PartialResult())
                text = partial.get("partial", "")
                if WAKE_WORD in text:
                    log.info(f"ğŸ¯ å”¤é†’è¯! (partial: {text})")
                    self.recognizer.Reset()
                    on_wake()

    def pause(self):
        self.paused = True

    def resume(self):
        self.paused = False
        self.recognizer.Reset()

    def stop(self):
        self.active = False
        if self._proc:
            self._proc.terminate()

# ============================================================
#  å°æ™ºå®¢æˆ·ç«¯ (é•¿è¿æ¥)
# ============================================================
class XiaozhiClient:
    def __init__(self, ws_url: str, device_id: str):
        self.ws_url = ws_url
        self.device_id = device_id
        self.session_id = None
        self.ws = None
        self.connected = False
        self.is_speaking = False  # æœåŠ¡ç«¯åœ¨è¯´è¯
        self.is_listening = False  # æ­£åœ¨å½•éŸ³
        self._rec_proc = None
        self._play_proc = None
        self._loop = None
        self._send_task = None

    async def connect(self):
        """å»ºç«‹é•¿è¿æ¥"""
        import websockets
        headers = {
            "Device-Id": self.device_id,
            "Client-Id": self.device_id,
            "Protocol-Version": "1",
        }
        log.info(f"ğŸ”— è¿æ¥ {self.ws_url}")
        self.ws = await websockets.connect(
            self.ws_url, max_size=None,
            additional_headers=headers,
            ping_interval=20, ping_timeout=20,
            close_timeout=10,
        )
        # å‘ hello
        hello = {
            "type": "hello",
            "version": 1,
            "transport": "websocket",
            "device_id": self.device_id,
            "device_name": "è€ä¸‰-æ ‘è“æ´¾",
            "features": {"mcp": False},
            "audio_params": {
                "format": "opus",
                "sample_rate": SAMPLE_RATE,
                "channels": CHANNELS,
                "frame_duration": FRAME_DURATION_MS,
            },
        }
        await self.ws.send(json.dumps(hello))
        log.info("ğŸ“¤ å·²å‘é€ hello")

        # ç­‰ hello å“åº”
        resp = await asyncio.wait_for(self.ws.recv(), timeout=10)
        try:
            data = json.loads(resp)
            self.session_id = data.get("session_id", "")
            log.info(f"âœ… è¿æ¥æˆåŠŸ, session: {self.session_id}")
            self.connected = True
        except Exception as e:
            log.error(f"æ¡æ‰‹å¤±è´¥: {e}, resp: {str(resp)[:200]}")
            return False
        return True

    async def message_loop(self):
        """æŒç»­æ¥æ”¶æ¶ˆæ¯"""
        try:
            async for message in self.ws:
                if isinstance(message, bytes):
                    # Opus éŸ³é¢‘ â†’ è§£ç æ’­æ”¾
                    try:
                        pcm = opus_to_pcm(message)
                        self._play_pcm(pcm)
                    except Exception:
                        pass
                else:
                    data = json.loads(message)
                    await self._handle(data)
        except Exception as e:
            log.error(f"è¿æ¥æ–­å¼€: {e}")
            self.connected = False

    async def _handle(self, msg: dict):
        t = msg.get("type", "")
        if t == "tts":
            state = msg.get("state", "")
            if state == "start":
                self.is_speaking = True
                log.info("ğŸ”Š æœåŠ¡ç«¯å¼€å§‹è¯´è¯")
            elif state == "sentence_start":
                log.info(f"ğŸ’¬ {msg.get('text', '')}")
            elif state == "stop":
                self.is_speaking = False
                log.info("ğŸ”Š æœåŠ¡ç«¯è¯´è¯ç»“æŸ")
        elif t == "stt":
            log.info(f"ğŸ¤ è¯†åˆ«: {msg.get('text', '')}")
        elif t == "llm":
            log.info(f"ğŸ¤– {msg.get('text', '')}")
        elif t == "hello":
            self.session_id = msg.get("session_id", self.session_id)
            log.info(f"hello å“åº”, session: {self.session_id}")

    def _play_pcm(self, pcm: bytes):
        """ç›´æ¥å†™å…¥ aplay è¿›ç¨‹"""
        try:
            if self._play_proc is None or self._play_proc.poll() is not None:
                self._play_proc = subprocess.Popen(
                    ["aplay", "-D", AUDIO_PLAY, "-f", "S16_LE",
                     "-r", str(SAMPLE_RATE), "-c", "1", "-q"],
                    stdin=subprocess.PIPE, stderr=subprocess.DEVNULL
                )
            self._play_proc.stdin.write(pcm)
            self._play_proc.stdin.flush()
        except Exception:
            self._play_proc = None

    async def on_wake_word(self):
        """å”¤é†’è¯è§¦å‘"""
        if not self.connected:
            log.warning("æœªè¿æ¥ï¼Œå¿½ç•¥å”¤é†’")
            return

        log.info("ğŸ™ï¸ å”¤é†’è¯è§¦å‘ï¼Œå¼€å§‹å¯¹è¯")

        # å¦‚æœæœåŠ¡ç«¯åœ¨è¯´è¯ï¼Œå…ˆæ‰“æ–­
        if self.is_speaking:
            abort = {"session_id": self.session_id, "type": "abort", "reason": "wake_word_detected"}
            await self.ws.send(json.dumps(abort))
            # å…³é—­æ’­æ”¾è¿›ç¨‹
            if self._play_proc:
                try:
                    self._play_proc.terminate()
                except Exception:
                    pass
                self._play_proc = None

        # å‘å”¤é†’è¯æ£€æµ‹æ¶ˆæ¯
        detect = {
            "session_id": self.session_id,
            "type": "listen",
            "state": "detect",
            "text": WAKE_WORD,
        }
        await self.ws.send(json.dumps(detect))

        # å‘å¼€å§‹ç›‘å¬
        start = {
            "session_id": self.session_id,
            "type": "listen",
            "state": "start",
            "mode": "auto",
        }
        await self.ws.send(json.dumps(start))

        # å¼€å§‹å½•éŸ³å‘é€
        self.is_listening = True
        self._send_task = asyncio.create_task(self._record_and_send())

    async def _record_and_send(self):
        """å½•éŸ³å¹¶é€šè¿‡ WebSocket å‘é€ Opus å¸§"""
        frame_bytes = FRAME_SIZE * 2
        self._rec_proc = subprocess.Popen(
            ["arecord", "-D", AUDIO_REC, "-f", "S16_LE",
             "-r", str(SAMPLE_RATE), "-c", "1", "-t", "raw", "-q"],
            stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
        )
        loop = asyncio.get_event_loop()
        log.info("ğŸ™ï¸ å½•éŸ³ä¸­...")
        try:
            while self.is_listening and self.connected:
                data = await loop.run_in_executor(None, self._rec_proc.stdout.read, frame_bytes)
                if len(data) == frame_bytes:
                    opus = pcm_to_opus(data)
                    await self.ws.send(opus)
        except Exception as e:
            log.error(f"å½•éŸ³å‘é€é”™è¯¯: {e}")
        finally:
            self._stop_recording()

    def _stop_recording(self):
        self.is_listening = False
        if self._rec_proc:
            try:
                self._rec_proc.terminate()
            except Exception:
                pass
            self._rec_proc = None

    async def stop_listening(self):
        """åœæ­¢å½•éŸ³"""
        self._stop_recording()
        if self._send_task:
            self._send_task.cancel()
        stop = {"session_id": self.session_id, "type": "listen", "state": "stop"}
        try:
            await self.ws.send(json.dumps(stop))
        except Exception:
            pass
        log.info("ğŸ™ï¸ åœæ­¢å½•éŸ³")


# ============================================================
#  ä¸»ç¨‹åº
# ============================================================
async def main(ws_url: str):
    device_id = f"pi-{uuid.uuid4().hex[:8]}"
    log.info(f"è®¾å¤‡ID: {device_id}")

    client = XiaozhiClient(ws_url, device_id)

    # è¿æ¥
    if not await client.connect():
        log.error("è¿æ¥å¤±è´¥ï¼Œé€€å‡º")
        return

    speak_async("æ‚Ÿç©ºä¸Šçº¿äº†")

    # å”¤é†’è¯ç›‘å¬
    listener = WakeWordListener()
    loop = asyncio.get_event_loop()

    def on_wake():
        listener.pause()
        asyncio.run_coroutine_threadsafe(client.on_wake_word(), loop)
        # ç­‰æœåŠ¡ç«¯è¯´å®Œåæ¢å¤ç›‘å¬
        def wait_and_resume():
            time.sleep(2)  # ç­‰å”¤é†’å¤„ç†
            while client.is_listening or client.is_speaking:
                time.sleep(0.5)
            time.sleep(1)
            listener.resume()
            log.info(f"ğŸ‘‚ ç»§ç»­ç›‘å¬: {WAKE_WORD}")
        threading.Thread(target=wait_and_resume, daemon=True).start()

    listener.start(on_wake)

    # æ¶ˆæ¯å¾ªç¯ï¼ˆä¿æŒé•¿è¿æ¥ï¼‰
    await client.message_loop()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å°æ™ºè¯­éŸ³å¯¹è¯å®¢æˆ·ç«¯")
    parser.add_argument("--ws", default="ws://192.168.0.69:8100/xiaozhi/v1/")
    parser.add_argument("--play-device", default=AUDIO_PLAY)
    parser.add_argument("--rec-device", default=AUDIO_REC)
    args = parser.parse_args()

    AUDIO_PLAY = args.play_device
    AUDIO_REC = args.rec_device

    asyncio.run(main(args.ws))
