#!/usr/bin/env python3
"""
å°æ™ºè¯­éŸ³å¯¹è¯å®¢æˆ·ç«¯ â€” è¿è¡Œåœ¨è€ä¸‰(æ ‘è“æ´¾)ä¸Š
å”¤é†’è¯: "ä¹è¿ª" (é€šè¿‡ vosk ç¦»çº¿è¯†åˆ«)
é€šè¿‡ WebSocket è¿æ¥å°æ™ºåç«¯æœåŠ¡ï¼Œå®ç°è¯­éŸ³å¯¹è¯

æµç¨‹:
1. vosk æŒç»­ç›‘å¬éº¦å…‹é£ï¼Œæ£€æµ‹å”¤é†’è¯ "ä¹è¿ª"
2. æ£€æµ‹åˆ°åè¿æ¥ WebSocketï¼Œå¼€å§‹å½•éŸ³å¹¶å‘é€ Opus å¸§
3. æœåŠ¡ç«¯ VAD æ£€æµ‹åˆ°é™éŸ³åå¤„ç† ASRâ†’LLMâ†’TTS
4. æ¥æ”¶ Opus éŸ³é¢‘å¸§è§£ç æ’­æ”¾
5. å¯¹è¯ç»“æŸå›åˆ°ç›‘å¬çŠ¶æ€
"""

import argparse
import asyncio
import json
import logging
import os
import subprocess
import struct
import sys
import threading
import time
import uuid
from collections import deque

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
log = logging.getLogger("xiaozhi")

# ============================================================
#  é…ç½®
# ============================================================
SAMPLE_RATE = 16000
CHANNELS = 1
FRAME_DURATION_MS = 60
FRAME_SIZE = SAMPLE_RATE * FRAME_DURATION_MS // 1000  # 960
AUDIO_PLAY = "plughw:3,0"
AUDIO_REC = "plughw:2,0"
WAKE_WORD = "ä¹è¿ª"
VOSK_MODEL = os.path.join(os.path.dirname(__file__), "models", "vosk-model-small-cn-0.22")
TALK_TIMEOUT = 15  # å¯¹è¯æœ€é•¿æ—¶é—´(ç§’)

# ============================================================
#  Opus ç¼–è§£ç 
# ============================================================
import opuslib_next as opuslib
_encoder = opuslib.Encoder(SAMPLE_RATE, CHANNELS, opuslib.APPLICATION_VOIP)
_decoder = opuslib.Decoder(SAMPLE_RATE, CHANNELS)


def pcm_to_opus(pcm: bytes) -> bytes:
    return _encoder.encode(pcm, FRAME_SIZE)


def opus_to_pcm(data: bytes) -> bytes:
    return _decoder.decode(data, FRAME_SIZE)


# ============================================================
#  æœ¬åœ°è¯­éŸ³ (espeak)
# ============================================================
def speak(text: str):
    """æœ¬åœ° TTS"""
    subprocess.run(
        f'espeak -v zh -s 320 --stdout "{text}" | aplay -D {AUDIO_PLAY} -q',
        shell=True, stderr=subprocess.DEVNULL
    )


def speak_async(text: str):
    threading.Thread(target=speak, args=(text,), daemon=True).start()


# ============================================================
#  å”¤é†’è¯æ£€æµ‹ (vosk ç¦»çº¿)
# ============================================================
class WakeWordListener:
    """ç”¨ vosk æŒç»­ç›‘å¬éº¦å…‹é£ï¼Œæ£€æµ‹å”¤é†’è¯"""

    def __init__(self, model_path=VOSK_MODEL, device=AUDIO_REC, wake_word=WAKE_WORD):
        from vosk import Model, KaldiRecognizer
        log.info(f"åŠ è½½ vosk æ¨¡å‹: {model_path}")
        self.model = Model(model_path)
        self.recognizer = KaldiRecognizer(self.model, SAMPLE_RATE)
        self.device = device
        self.wake_word = wake_word
        self.active = True
        self.paused = False  # å¯¹è¯æœŸé—´æš‚åœæ£€æµ‹

    def listen(self, on_wake):
        """é˜»å¡å¼ç›‘å¬ï¼Œæ£€æµ‹åˆ°å”¤é†’è¯è°ƒç”¨ on_wake()"""
        log.info(f"ğŸ‘‚ ç›‘å¬å”¤é†’è¯: {self.wake_word}")
        proc = subprocess.Popen(
            ["arecord", "-D", self.device, "-f", "S16_LE",
             "-r", str(SAMPLE_RATE), "-c", "1", "-t", "raw", "-q"],
            stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
        )
        chunk_size = 4000  # ~125ms of audio
        try:
            while self.active:
                data = proc.stdout.read(chunk_size)
                if not data:
                    break
                if self.paused:
                    continue
                if self.recognizer.AcceptWaveform(data):
                    result = json.loads(self.recognizer.Result())
                    text = result.get("text", "")
                    if text:
                        log.debug(f"vosk: {text}")
                        if self.wake_word in text:
                            log.info(f"ğŸ¯ å”¤é†’è¯æ£€æµ‹åˆ°! ({text})")
                            on_wake()
                else:
                    partial = json.loads(self.recognizer.PartialResult())
                    text = partial.get("partial", "")
                    if self.wake_word in text:
                        log.info(f"ğŸ¯ å”¤é†’è¯æ£€æµ‹åˆ°! (partial: {text})")
                        self.recognizer.Reset()
                        on_wake()
        finally:
            proc.terminate()

    def pause(self):
        self.paused = True

    def resume(self):
        self.recognizer.Reset()
        self.paused = False

    def stop(self):
        self.active = False


# ============================================================
#  å°æ™º WebSocket å¯¹è¯
# ============================================================
async def do_conversation(ws_url: str, device_id: str):
    """è¿›è¡Œä¸€æ¬¡å®Œæ•´å¯¹è¯:è¿æ¥â†’å½•éŸ³â†’ç­‰å›å¤â†’æ’­æ”¾â†’æ–­å¼€"""
    import websockets

    log.info(f"ğŸ”— è¿æ¥ {ws_url}")
    try:
        async with websockets.connect(ws_url, max_size=None, close_timeout=5) as ws:
            # === æ¡æ‰‹ ===
            hello = {
                "type": "hello",
                "device_id": device_id,
                "device_name": "è€ä¸‰-æ ‘è“æ´¾",
                "device_mac": "AA:BB:CC:DD:EE:FF",
                "token": "",
                "features": {"mcp": False}
            }
            await ws.send(json.dumps(hello))

            resp = await asyncio.wait_for(ws.recv(), timeout=10)
            data = json.loads(resp)
            if data.get("type") != "hello" or not data.get("session_id"):
                log.error(f"æ¡æ‰‹å¤±è´¥: {data}")
                return
            session_id = data["session_id"]
            log.info(f"âœ… æ¡æ‰‹æˆåŠŸ, session: {session_id}")

            # === å‘é€ listen start ===
            await ws.send(json.dumps({"type": "listen", "state": "start", "mode": "auto"}))

            # === å½•éŸ³å¹¶å‘é€ ===
            stop_recording = threading.Event()
            rec_proc = subprocess.Popen(
                ["arecord", "-D", AUDIO_REC, "-f", "S16_LE",
                 "-r", str(SAMPLE_RATE), "-c", "1", "-t", "raw", "-q"],
                stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
            )

            async def send_audio():
                frame_bytes = FRAME_SIZE * 2
                loop = asyncio.get_event_loop()
                while not stop_recording.is_set():
                    data = await loop.run_in_executor(None, rec_proc.stdout.read, frame_bytes)
                    if len(data) == frame_bytes:
                        try:
                            opus = pcm_to_opus(data)
                            await ws.send(opus)
                        except Exception:
                            break

            # === æ¥æ”¶æ¶ˆæ¯ ===
            player_queue = deque()
            tts_done = asyncio.Event()
            conversation_done = asyncio.Event()

            def play_audio():
                """æ’­æ”¾çº¿ç¨‹"""
                play_proc = None
                while not conversation_done.is_set():
                    if player_queue:
                        buf = bytearray()
                        while player_queue and len(buf) < SAMPLE_RATE * 2:
                            buf.extend(player_queue.popleft())
                        if buf:
                            try:
                                play_proc = subprocess.Popen(
                                    ["aplay", "-D", AUDIO_PLAY, "-f", "S16_LE",
                                     "-r", str(SAMPLE_RATE), "-c", "1", "-q"],
                                    stdin=subprocess.PIPE, stderr=subprocess.DEVNULL
                                )
                                play_proc.stdin.write(bytes(buf))
                                play_proc.stdin.close()
                                play_proc.wait(timeout=10)
                            except Exception as e:
                                log.error(f"æ’­æ”¾é”™è¯¯: {e}")
                    else:
                        time.sleep(0.01)

            play_thread = threading.Thread(target=play_audio, daemon=True)
            play_thread.start()

            async def recv_messages():
                try:
                    async for message in ws:
                        if isinstance(message, bytes):
                            try:
                                pcm = opus_to_pcm(message)
                                player_queue.append(pcm)
                            except Exception:
                                pass
                        else:
                            msg = json.loads(message)
                            msg_type = msg.get("type", "")

                            if msg_type == "tts":
                                state = msg.get("state", "")
                                if state == "start":
                                    log.info("ğŸ”Š å¼€å§‹æ’­æ”¾å›å¤")
                                    stop_recording.set()
                                    rec_proc.terminate()
                                elif state == "sentence_start":
                                    log.info(f"ğŸ’¬ {msg.get('text', '')}")
                                elif state == "stop":
                                    log.info("ğŸ”Š å›å¤ç»“æŸ")
                                    # ç­‰éŸ³é¢‘æ’­å®Œ
                                    await asyncio.sleep(1)
                                    tts_done.set()
                                    return

                            elif msg_type == "stt":
                                text = msg.get("text", "")
                                log.info(f"ğŸ¤ è¯†åˆ«: {text}")
                                # è¯†åˆ«åˆ°æ–‡æœ¬ååœæ­¢å½•éŸ³
                                stop_recording.set()
                                rec_proc.terminate()

                            elif msg_type == "llm":
                                log.info(f"ğŸ¤– {msg.get('text', '')}")

                except Exception as e:
                    log.error(f"æ¥æ”¶é”™è¯¯: {e}")

            # å¹¶è¡Œ: å‘éŸ³é¢‘ + æ”¶æ¶ˆæ¯
            send_task = asyncio.create_task(send_audio())
            recv_task = asyncio.create_task(recv_messages())

            # è¶…æ—¶ä¿æŠ¤
            try:
                await asyncio.wait_for(tts_done.wait(), timeout=30)
            except asyncio.TimeoutError:
                log.warning("â° å¯¹è¯è¶…æ—¶")

            # æ¸…ç†
            stop_recording.set()
            rec_proc.terminate()
            conversation_done.set()
            send_task.cancel()
            recv_task.cancel()

            # ç­‰æ’­æ”¾çº¿ç¨‹ç»“æŸ
            time.sleep(1)
            log.info("âœ… å¯¹è¯ç»“æŸ")

    except Exception as e:
        log.error(f"å¯¹è¯é”™è¯¯: {e}")


# ============================================================
#  ä¸»ç¨‹åº
# ============================================================
def main():
    parser = argparse.ArgumentParser(description="å°æ™ºè¯­éŸ³å¯¹è¯å®¢æˆ·ç«¯ (è€ä¸‰)")
    parser.add_argument("--ws", default="ws://192.168.0.69:8100/xiaozhi/v1/",
                        help="å°æ™º WebSocket åœ°å€")
    parser.add_argument("--play-device", default=AUDIO_PLAY, help="æ’­æ”¾è®¾å¤‡")
    parser.add_argument("--rec-device", default=AUDIO_REC, help="å½•éŸ³è®¾å¤‡")
    args = parser.parse_args()

    global AUDIO_PLAY, AUDIO_REC
    AUDIO_PLAY = args.play_device
    AUDIO_REC = args.rec_device

    device_id = f"pi-{uuid.uuid4().hex[:8]}"
    log.info(f"è®¾å¤‡ID: {device_id}")

    # å¯åŠ¨è¯­éŸ³
    speak("ä¹è¿ªä¸Šçº¿äº†")

    # å”¤é†’è¯ç›‘å¬
    listener = WakeWordListener(device=args.rec_device)

    def on_wake():
        listener.pause()
        speak("æˆ‘åœ¨")
        try:
            asyncio.run(do_conversation(args.ws, device_id))
        except Exception as e:
            log.error(f"å¯¹è¯å¤±è´¥: {e}")
        finally:
            listener.resume()
            log.info(f"ğŸ‘‚ ç»§ç»­ç›‘å¬å”¤é†’è¯: {WAKE_WORD}")

    try:
        listener.listen(on_wake)
    except KeyboardInterrupt:
        log.info("é€€å‡º")
        listener.stop()


if __name__ == "__main__":
    main()
